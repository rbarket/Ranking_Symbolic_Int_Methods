{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5cc396b",
   "metadata": {},
   "source": [
    "# Example of how to load model and make method prediction given an integrand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8885057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from src.utils.config import load_config\n",
    "from src.utils.io import load_vocab, load_precomputed_positions\n",
    "from src.utils.tree_utils import get_prefix_data_with_paths, path_to_index\n",
    "\n",
    "from src.models.tree_transformer import TreeTransformer\n",
    "\n",
    "from scripts.inference import maybe_strip_module_prefix\n",
    "from src.data.dataset import PrefixExpressionDataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3440aad1",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7284edea",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = load_config(\"configs/train_config.yaml\")\n",
    "vocab = load_vocab(cfg) # all possible tokens in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0091f16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model definition\n",
    "model = TreeTransformer(\n",
    "        vocab_size=len(vocab),\n",
    "        d_model=cfg.model.d_model,\n",
    "        nhead=cfg.model.heads,\n",
    "        num_layers=cfg.model.layers,\n",
    "        dim_feedforward=cfg.model.dim_feedforward,\n",
    "        num_labels=12, # number of possible methods in the dataset based on maple's int methods (not including lookup)\n",
    "        n=cfg.tree.branching_factor,\n",
    "        k=cfg.tree.depth\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "831e0f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the saved model\n",
    "device = torch.device(\"cpu\") # force to use cpu, normally gpu for training and the inference script\n",
    "checkpoint_path = 'models/ranking/ranking_best.pth'\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfd37043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TreeTransformer(\n",
       "  (embedding): Embedding(100, 40)\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=40, out_features=40, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=40, out_features=128, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=128, out_features=40, bias=True)\n",
       "        (norm1): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=40, out_features=12, bias=True)\n",
       "  (cls_dropout): Dropout(p=0.1, inplace=False)\n",
       "  (cls_norm): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If the checkpoint was saved with DataParallel, keys may have 'module.' prefix\n",
    "state_dict = checkpoint.get(\"model_state_dict\", checkpoint)\n",
    "state_dict = maybe_strip_module_prefix(state_dict) # function to remove 'module.' if running on CPU\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b801d348",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f6b8ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>integrand</th>\n",
       "      <th>prefix</th>\n",
       "      <th>integral</th>\n",
       "      <th>label_original</th>\n",
       "      <th>source</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2*2^(1/2)*x^(1/2)*tan(1)^(1/2)</td>\n",
       "      <td>[[CLS], mul, INT+, 2, mul, pow, INT+, 2, div, ...</td>\n",
       "      <td>4/3*x^(3/2)*2^(1/2)*tan(1)^(1/2)</td>\n",
       "      <td>[72, 72, -1, 115, -1, -1, -1, -1, -1, -1, 72, 72]</td>\n",
       "      <td>elementary</td>\n",
       "      <td>[0.0, 0.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2*x^2*arctanh(x)+ln(x)</td>\n",
       "      <td>[[CLS], add, mul, INT+, 2, mul, pow, x, INT+, ...</td>\n",
       "      <td>2/3*x^3*arctanh(x)+1/3+1/3*x^2+x*ln(x)+2/3*ln(...</td>\n",
       "      <td>[139, -1, 139, 143, -1, -1, 130, -1, -1, -1, -...</td>\n",
       "      <td>elementary</td>\n",
       "      <td>[0.6923076923076923, -1.0, 0.6923076923076923,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/x*sin(cosh(5))</td>\n",
       "      <td>[[CLS], mul, pow, x, INT-, 1, sin, cosh, INT+,...</td>\n",
       "      <td>sin(cosh(5))*ln(x)</td>\n",
       "      <td>[83, -1, -1, 83, 83, -1, 83, -1, -1, -1, -1, -1]</td>\n",
       "      <td>elementary</td>\n",
       "      <td>[0.0, -1.0, -1.0, 0.0, 0.0, -1.0, 0.0, -1.0, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3+Pi-x</td>\n",
       "      <td>[[CLS], add, INT-, CONST1, add, Pi, mul, INT-,...</td>\n",
       "      <td>1/2*x*(-x+2*Pi-6)</td>\n",
       "      <td>[54, -1, 54, 54, 58, -1, 58, -1, -1, -1, 54, 54]</td>\n",
       "      <td>elementary</td>\n",
       "      <td>[0.0, -1.0, 0.0, 0.0, 1.0, -1.0, 1.0, -1.0, -1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16*x^2/sin(2)^2</td>\n",
       "      <td>[[CLS], mul, INT+, CONST2, mul, pow, x, INT+, ...</td>\n",
       "      <td>16/3*x^3/sin(2)^2</td>\n",
       "      <td>[62, -1, -1, 62, 62, -1, 62, -1, -1, -1, 62, 62]</td>\n",
       "      <td>elementary</td>\n",
       "      <td>[0.0, -1.0, -1.0, 0.0, 0.0, -1.0, 0.0, -1.0, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        integrand  \\\n",
       "0  2*2^(1/2)*x^(1/2)*tan(1)^(1/2)   \n",
       "1          2*x^2*arctanh(x)+ln(x)   \n",
       "2                1/x*sin(cosh(5))   \n",
       "3                         -3+Pi-x   \n",
       "4                 16*x^2/sin(2)^2   \n",
       "\n",
       "                                              prefix  \\\n",
       "0  [[CLS], mul, INT+, 2, mul, pow, INT+, 2, div, ...   \n",
       "1  [[CLS], add, mul, INT+, 2, mul, pow, x, INT+, ...   \n",
       "2  [[CLS], mul, pow, x, INT-, 1, sin, cosh, INT+,...   \n",
       "3  [[CLS], add, INT-, CONST1, add, Pi, mul, INT-,...   \n",
       "4  [[CLS], mul, INT+, CONST2, mul, pow, x, INT+, ...   \n",
       "\n",
       "                                            integral  \\\n",
       "0                   4/3*x^(3/2)*2^(1/2)*tan(1)^(1/2)   \n",
       "1  2/3*x^3*arctanh(x)+1/3+1/3*x^2+x*ln(x)+2/3*ln(...   \n",
       "2                                 sin(cosh(5))*ln(x)   \n",
       "3                                  1/2*x*(-x+2*Pi-6)   \n",
       "4                                  16/3*x^3/sin(2)^2   \n",
       "\n",
       "                                      label_original      source  \\\n",
       "0  [72, 72, -1, 115, -1, -1, -1, -1, -1, -1, 72, 72]  elementary   \n",
       "1  [139, -1, 139, 143, -1, -1, 130, -1, -1, -1, -...  elementary   \n",
       "2   [83, -1, -1, 83, 83, -1, 83, -1, -1, -1, -1, -1]  elementary   \n",
       "3   [54, -1, 54, 54, 58, -1, 58, -1, -1, -1, 54, 54]  elementary   \n",
       "4   [62, -1, -1, 62, 62, -1, 62, -1, -1, -1, 62, 62]  elementary   \n",
       "\n",
       "                                               label  \n",
       "0  [0.0, 0.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, ...  \n",
       "1  [0.6923076923076923, -1.0, 0.6923076923076923,...  \n",
       "2  [0.0, -1.0, -1.0, 0.0, 0.0, -1.0, 0.0, -1.0, -...  \n",
       "3  [0.0, -1.0, 0.0, 0.0, 1.0, -1.0, 1.0, -1.0, -1...  \n",
       "4  [0.0, -1.0, -1.0, 0.0, 0.0, -1.0, 0.0, -1.0, -...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The integrand column is in string form (Maple readable format), but we use the prefix expression form for the model\n",
    "df = pd.read_parquet('data/processed/train_data.parquet')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6370a4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of methods to integer labels\n",
    "method_dict = {'default': 0, \n",
    "            'ddivides': 1, \n",
    "            'parts': 2,\n",
    "            'risch': 3,\n",
    "            'norman': 4,\n",
    "            'trager': 5,\n",
    "            'parallelrisch': 6,\n",
    "            'meijerg': 7, \n",
    "            'elliptic': 8,\n",
    "            'pseudoelliptic':9,\n",
    "            'gosper': 10,\n",
    "            'orering': 11}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "90ae16ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x^2*(3*x^3*cosh(2*x^3)+sinh(2*x^3))\n",
      "['[CLS]' 'mul' 'pow' 'x' 'INT+' '2' 'add' 'mul' 'INT+' 'CONST1' 'mul'\n",
      " 'pow' 'x' 'INT+' 'CONST1' 'cosh' 'mul' 'INT+' '2' 'pow' 'x' 'INT+'\n",
      " 'CONST1' 'sinh' 'mul' 'INT+' '2' 'pow' 'x' 'INT+' 'CONST1']\n",
      "[-1.         -1.         -1.          0.         -1.         -1.\n",
      " -1.          0.37755102 -1.         -1.         -1.          1.        ]\n"
     ]
    }
   ],
   "source": [
    "# Here is an example from the dataset. You can change the sample_n to try different examples.\n",
    "sample_n = 793966\n",
    "\n",
    "print(df['integrand'].iloc[sample_n])\n",
    "print(df['prefix'].iloc[sample_n])\n",
    "print(df['label'].iloc[sample_n])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3160850a",
   "metadata": {},
   "source": [
    "For the given integrand, we see that three methods produce an answer, and the rest fail (denoted by -1). From our method dictionary, we see that risch produced the answer with the shortest DAG size, meijerg produces an answer a bit longer than risch, and orering produces the longest answer. Lets take the integrand and integrate it in Maple with each of the following methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780a8ab8",
   "metadata": {},
   "source": [
    "#### risch result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b70042",
   "metadata": {},
   "source": [
    "![risch result](notebook_images/f1_risch.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6e940a",
   "metadata": {},
   "source": [
    "#### meijerg result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6aa9f5f",
   "metadata": {},
   "source": [
    "![meijerg result](notebook_images/f1_meijerg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022e5bb3",
   "metadata": {},
   "source": [
    "#### orering result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ba57dd",
   "metadata": {},
   "source": [
    "![orering result](notebook_images/f1_orering.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51042586",
   "metadata": {},
   "source": [
    "## Prepare Input for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "9cafea05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2,  3,  6,  9, 10,  8,  3,  6, 19,  8, 16,  8,  3,  6,  8,  6,  3,  9,\n",
       "        17,  7, 16,  8,  9, 10, 19,  8,  6,  4, 17,  6,  8,  6, 18,  8, 16,  8])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expr = df['prefix'].iloc[sample_n]\n",
    "tokens, path_list = get_prefix_data_with_paths(expr) # path list is the one-hot encoding of path to node from root\n",
    "token_ids = torch.tensor([vocab.get(tok, 1) for tok in tokens], dtype=torch.long) # converts tokens to ids, unknown token is 1\n",
    "token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b218d3d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 1.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tree positional encoding for each token\n",
    "token_mask = torch.zeros(token_ids.shape, dtype=torch.bool) # only used during training to denote pad tokens, hence all zeros here\n",
    "positions = load_precomputed_positions(cfg)\n",
    "k = cfg.tree.depth\n",
    "pos_tensor = torch.stack([\n",
    "                positions[min(len(path), k)][path_to_index(path[:min(len(path), k)])]\n",
    "                for path in path_list\n",
    "            ])\n",
    "pos_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "d6f37d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make all the same shape of batch size 1\n",
    "token_ids   = token_ids.unsqueeze(0).to(device)         # [1, L], long\n",
    "pos_tensor  = pos_tensor.unsqueeze(0).to(device)        # [1, L, d_model], float\n",
    "token_mask  = token_mask.unsqueeze(0).to(device)        # [1, L], bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a6fb6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4194, 0.2343, 0.3913, 0.6850, 0.7282, 0.6633, 0.0702, 0.9550, 0.9121,\n",
       "        0.4445, 0.0958, 0.9919], grad_fn=<RoundBackward1>)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = model(token_ids, pos_tensor, token_mask).squeeze()  # [1, L, num_labels]\n",
    "torch.round(torch.sigmoid(res), decimals=4)  # ordering of methods (ascending)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162e042e",
   "metadata": {},
   "source": [
    "Note that the model is predicting scaled DAG size, so a smaller value is better/ \n",
    "\n",
    "We see from the output, the model first tries to predict methods that are going to fail. This is where the classifier stage comes in to filter out the methods that are likely to fail (this will be included in the examples later). For the methods that do succeed, we predict to try risch first, then meijerg, then orering. We are able to correctly predict the best method for DAG size, risch. Although the first method is the only one that actually matters, we note that the model is able to get the complete ordering correctly.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TreeLSTM_DGL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
